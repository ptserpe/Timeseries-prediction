{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.optimizers import RMSprop\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sklearn.preprocessing as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"export_dataframe.csv\") \n",
    "#need of an array with the id of the papers\n",
    "data = data.sort_index(axis=1, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True, by=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = []\n",
    "\n",
    "headers = data.columns\n",
    "for i in range(0, 45):\n",
    "    data = data.drop([headers[i]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = data\n",
    "years = years.drop('ids', axis = 1)\n",
    "years = years.drop('2018', axis = 1)\n",
    "all_years = np.asarray(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(all_years)\n",
    "deleted_years = []\n",
    "for i in range(l):\n",
    "    if any(j != 0 for j in all_years[i]):\n",
    "        deleted_years.append(all_years[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(deleted_years)\n",
    "smaller_array = []\n",
    "for i in range(l):\n",
    "    temp_count = 0\n",
    "    for j in deleted_years[i]:\n",
    "        temp_count = temp_count + j\n",
    "        if temp_count > 90:\n",
    "            smaller_array.append(deleted_years[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "LSTMs are sensitive to the scale of the input data, specifically when the sigmoid or tanh activation functions are used. It’s generally a good practice to rescale the data to the range of [0, 1] or [-1, 1], also called normalizing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas import Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_transform_series(series, window_size):\n",
    "    # containers for input/output pairs\n",
    "    X,y = [],[]\n",
    "    l = len(series)\n",
    "    for idx in range(l - window_size):\n",
    "        X.append(series[idx:idx+window_size])\n",
    "    \n",
    "    y = series[window_size:]\n",
    "    \n",
    "    # reshape each \n",
    "    X = np.asarray(X)\n",
    "    X.shape = (np.shape(X)[0:2])\n",
    "    y = np.asarray(y)\n",
    "    y.shape = (len(y),1)\n",
    "    \n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1():\n",
    "    \n",
    "    window_size = 5\n",
    "\n",
    "    lstm_model.add(LSTM( 5, activation = 'relu', input_shape=(5, 1), return_sequences = True))\n",
    "    lstm_model.add(LSTM( 5, activation = 'relu', return_sequences = False))\n",
    "    lstm_model.add(Dropout(0.3))\n",
    "    lstm_model.add(Dense(1))\n",
    "    lstm_model.compile(optimizer='Adam',  metrics = ['accuracy'],loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = Sequential()\n",
    "model1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(X, y):\n",
    "    #X = np.asarray(np.reshape(X, (X.shape[0], window_size, 1)))\n",
    "    predict = lstm_model.predict(X)\n",
    "    error = lstm_model.evaluate(X, y, verbose=0)\n",
    "    acc = mean_squared_error(predict, y)\n",
    "    return predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in smaller_array:\n",
    "    \n",
    "    window_size = 5\n",
    "    X, y = window_transform_series(i, window_size = window_size)\n",
    "\n",
    "    train_test_split = int(np.ceil(2*len(y)/float(3)))   # set the split point\n",
    "    \n",
    "\n",
    "\n",
    "          # partition the training set\n",
    "    X_train = X[:train_test_split,:]\n",
    "    y_train = y[:train_test_split]\n",
    "\n",
    "            # keep the last chunk for testing\n",
    "    X_test = X[train_test_split:,:]\n",
    "    y_test = y[train_test_split:]\n",
    "\n",
    "            # NOTE: to use keras's RNN LSTM module our input must be reshaped to [samples, window size, stepsize] \n",
    "    X_train = np.asarray(np.reshape(X_train, (X_train.shape[0], window_size, 1)))\n",
    "    X_test = np.asarray(np.reshape(X_test, (X_test.shape[0], window_size, 1)))\n",
    "\n",
    "    lstm_model.fit(X_train, y_train, epochs=100, batch_size=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#καλουμε την απο πανω συνάρτηση για train και test \n",
    "#μετά την καλουμε για τα testcases αφου πρώτα έχουμε καλεσει την window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case1 = [10 ,13 ,6 ,3 ]\n",
    "test_case2 = [1 ,13, 6 ,9 ,13, 12 ,8 ,4 ,1]\n",
    "test_case3 = [19, 19 ,39, 24 ,26, 21,16 ,13 ,14, 2,0, 11, 5, 7, 6, 3 ]\n",
    "test_case4 = [10 ,59 ,84 ,126 ,163 ,174 ,195 ,210 ,196, 204 ,187 ,188 ,200, 173, 180, 157, 136 ,133 ]\n",
    "test_case5 = [10 ,34 ,35 ,49, 73, 64, 68, 44, 34, 32 ,14 ]\n",
    "test_case6 = [5 ,31 ,31 ,55 ,89 ,99 ,142 ,152 ,152]\n",
    "test_case7 = [3,11,17,44,47,74,94,99,126,142,131]\n",
    "test_case8 = [1,4,18,42,43,32,37,80,50,49,41,53,39,38,39,35,33,30,20]\n",
    "test_case9 = [12,7,22,15,31,31,24,27,26,31,28,22]\n",
    "test_case10 = [12,36,45,45,49,59,58,41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = []\n",
    "#test_cases.append(test_case1) only for window_size = 1\n",
    "test_cases.append(test_case2)\n",
    "test_cases.append(test_case3)\n",
    "test_cases.append(test_case4)\n",
    "test_cases.append(test_case5)\n",
    "test_cases.append(test_case6)\n",
    "test_cases.append(test_case7)\n",
    "test_cases.append(test_case8)\n",
    "test_cases.append(test_case9)\n",
    "test_cases.append(test_case10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#error of predict για y_train και y_test:\n",
    "inversed_X = []\n",
    "inversed_y = []\n",
    "inversed_y = scaler.inverse_transform(y_train)\n",
    "\n",
    "for i in X_train:\n",
    "    inversed_X.append(scaler.inverse_transform(i))\n",
    "inversed_X = np.asarray(inversed_X)\n",
    "X = np.asarray(np.reshape(inversed_X,(inversed_X.shape[0], window_size, 1)))\n",
    "train_prediction = prediction(X, inversed_y )\n",
    "\n",
    "inversed_X = []\n",
    "inversed_y = []\n",
    "inversed_y = scaler.inverse_transform(y_test)\n",
    "\n",
    "for i in X_test:\n",
    "    inversed_X.append(scaler.inverse_transform(i))\n",
    "inversed_X = np.asarray(inversed_X)\n",
    "test_prediction = prediction(inversed_X, inversed_y )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the test cases:\n",
    "\n",
    "predictionsOfTestCases = []\n",
    "\n",
    "for i in range(1,9):\n",
    "    X,y = window_transform_series(test_cases[i], window_size)\n",
    "    X = np.asarray(np.reshape(X,(X.shape[0], window_size, 1)))\n",
    "    temp = prediction(X,y)\n",
    "    predictionsOfTestCases.append(temp)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
